{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7e67785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset\n",
      "Plain prompt\n",
      "Fine-tuned\n",
      "T5-small\n",
      "SDXL\n",
      "Generated \n",
      "Images\n",
      "Concatenate\n",
      "Evaluation\n",
      "Plain prompt\n",
      "Structured information\n",
      "Fig. 2. An overview of the StructuredPrompter framework.\n",
      "language model during empirical evaluation. In total, the val-\n",
      "idation set contains 100 prompts, each paired with manually\n",
      "extracted structured information.\n",
      "3.2. Augmented Prompts\n",
      "Given a plain natural language prompt X as input and the\n",
      "GPT-4o–extracted structured information Y as ground truth,\n",
      "we fine-tune the language model f(·) to predict ˆY . The fine-\n",
      "tuning process is optimized with cross-entropy loss, as shown\n",
      "in the following equations:\n",
      "ˆY = f(X),\n",
      "(1)\n",
      "LCE = −\n",
      "N\n",
      "X\n",
      "i=1\n",
      "Yi log ˆYi,\n",
      "(2)\n",
      "where N is the number of tokens in the structured output,\n",
      "Yi is the ground-truth token distribution at position i, and ˆYi\n",
      "is the predicted probability distribution over the vocabulary at\n",
      "position i.\n",
      "The training process is evaluated on the validation set ev-\n",
      "ery five epochs. If performance does not improve within the\n",
      "subsequent five epochs, we consider the training to have con-\n",
      "verged.\n",
      "In this work, we employ T5-small as the language model\n",
      "for structured information extraction. On the validation set, it\n",
      "achieved scores above 0.98 in both BLEU and ROUGE, con-\n",
      "firming its reliability. Its compact model size further demon-\n",
      "strates the feasibility of lightweight tuple extraction. Detailed\n",
      "statistics are reported in Table 1.\n",
      "The extracted structured information is then concate-\n",
      "nated with plain natural language prompts to form augmented\n",
      "prompts, which are provided as inputs to Stable Diffusion XL\n",
      "for image generation. This process requires no modifications\n",
      "to the diffusion model and adds minimal overhead, making it\n",
      "portable across text-to-image models.\n",
      "3.3. Evaluation\n",
      "Spatial Relationships. We employ Qwen2.5-VL-3B-Instruct [30]\n",
      "as a judge to verify whether the generated images correctly\n",
      "convey the information specified in the plain prompts. For\n",
      "instance, given the prompt “B is on the right of A” and a gen-\n",
      "erated image, we query Qwen2.5-VL-3B-Instruct with “Is\n",
      "B on the right of A? Please answer Yes or No.” A correctly\n",
      "generated image should support a Yes response.\n",
      "In addition to spatial relationships, we also evaluate color\n",
      "and shape alignment. The results are in the Table 2.\n",
      "Image Quality. We further assess the overall visual qual-\n",
      "ity of the generated images using the Inception Score [31].\n",
      "4. EXPERIMENTS\n",
      "4.1. Implementation Details\n",
      "We conduct experiments using three random seeds (40, 41,\n",
      "and 42). The training batch size is 4 with a gradient accumu-\n",
      "lation step of 8. The learning rate is set to 1e-4, optimized\n",
      "using Adam with 10 warm-up steps and a weight decay of\n",
      "0.01. All experiments are implemented in PyTorch 2.5.1 and\n",
      "Transformers 4.50, and executed on an NVIDIA A100 GPU.\n",
      "Additional details are available in the GitHub repository of\n",
      "this work 1.\n",
      "4.2. Impact Of Parameter Scale\n",
      "As shown in Table 1, we adopt fine-tuned T5-small as the\n",
      "backbone model for structured information extraction. Us-\n",
      "ing 500 samples generated with GPT-4o, it achieves a BLEU\n",
      "score of 0.98 and a ROUGE score of 0.99.\n",
      "These results\n",
      "demonstrate that T5-small is a lightweight yet effective ex-\n",
      "tractor of structured information. In contrast, Llama-3.2-1B\n",
      "1The code and data will be publicly available upon publication at\n",
      "https://github.com/Sander445/StructuredPrompter.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz # PyMuPDF\n",
    "\n",
    "pdf_path = r\"C:\\Users\\shrinath\\OneDrive\\Desktop\\texttoimage.pdf\"\n",
    "def extract_text_pymupdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = []\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        text.append(page.get_text())\n",
    "    doc.close()\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "pdf_text = extract_text_pymupdf(pdf_path)\n",
    "print(pdf_text[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ee044d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
