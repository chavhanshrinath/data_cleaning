{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7e67785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset\n",
      "Plain prompt\n",
      "Fine-tuned\n",
      "T5-small\n",
      "SDXL\n",
      "Gene\n"
     ]
    }
   ],
   "source": [
    "import fitz # PyMuPDF\n",
    "\n",
    "pdf_path = r\"C:\\Users\\shrinath\\OneDrive\\Desktop\\texttoimage.pdf\"\n",
    "def extract_text_pymupdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = []\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        text.append(page.get_text())\n",
    "    doc.close()\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "pdf_text = extract_text_pymupdf(pdf_path)\n",
    "print(pdf_text[2][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4ee044d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Dataset Plain prompt Fine-tuned T5-small SDXL Generated\\xa0 Images '\n",
      " 'Concatenate Evaluation Plain prompt Structured information Fig. 2. An '\n",
      " 'overview of the StructuredPrompter framework. language model during '\n",
      " 'empirical evaluation. In total, the validation set contains 100 prompts, '\n",
      " 'each paired with manually extracted structured information. 3.2. Augmented '\n",
      " 'Prompts Given a plain natural language prompt X as input and the '\n",
      " 'GPT-4o–extracted structured information Y as ground truth, we fine-tune the '\n",
      " 'language model f(·) to predict ˆY . The finetuning process is optimized with '\n",
      " 'cross-entropy loss, as shown in the following equations: ˆY = f(X), (1) LCE '\n",
      " '= − N X i=1 Yi log ˆYi, (2) where N is the number of tokens in the '\n",
      " 'structured output, Yi is the ground-truth token distribution at position i, '\n",
      " 'and ˆYi is the predicted probability distribution over the vocabulary at '\n",
      " 'position i. The training process is evaluated on the validation set every '\n",
      " 'five epochs. If performance does not improve within the subsequent five '\n",
      " 'epochs, we consider the training to have converged. In this work, we employ '\n",
      " 'T5-small as the language model for structured information extraction. On the '\n",
      " 'validation set, it achieved scores above 0.98 in both BLEU and ROUGE, '\n",
      " 'confirming its reliability. Its compact model size further demonstrates the '\n",
      " 'feasibility of lightweight tuple extraction. Detailed statistics are '\n",
      " 'reported in Table 1. The extracted structured information is then '\n",
      " 'concatenated with plain natural language prompts to form augmented prompts, '\n",
      " 'which are provided as inputs to Stable Diffusion XL for image generation. '\n",
      " 'This process requires no modifications to the diffusion model and adds '\n",
      " 'minimal overhead, making it portable across text-to-image models. 3.3. '\n",
      " 'Evaluation Spatial Relationships. We employ Qwen2.5-VL-3B-Instruct [30] as a '\n",
      " 'judge to verify whether the generated images correctly convey the '\n",
      " 'information specified in the plain prompts. For instance, given the prompt '\n",
      " '“B is on the right of A” and a generated image, we query '\n",
      " 'Qwen2.5-VL-3B-Instruct with “Is B on the right of A? Please answer Yes or '\n",
      " 'No.” A correctly generated image should support a Yes response. In addition '\n",
      " 'to spatial relationships, we also evaluate color and shape alignment. The '\n",
      " 'results are in the Table 2. Image Quality. We further assess the overall '\n",
      " 'visual quality of the generated images using the Inception Score [31]. 4. '\n",
      " 'EXPERIMENTS 4.1. Implementation Details We conduct experiments using three '\n",
      " 'random seeds (40, 41, and 42). The training batch size is 4 with a gradient '\n",
      " 'accumulation step of 8. The learning rate is set to 1e-4, optimized using '\n",
      " 'Adam with 10 warm-up steps and a weight decay of 0.01. All experiments are '\n",
      " 'implemented in PyTorch 2.5.1 and Transformers 4.50, and executed on an '\n",
      " 'NVIDIA A100 GPU. Additional details are available in the GitHub repository '\n",
      " 'of this work 1. 4.2. Impact Of Parameter Scale As shown in Table 1, we adopt '\n",
      " 'fine-tuned T5-small as the backbone model for structured information '\n",
      " 'extraction. Using 500 samples generated with GPT-4o, it achieves a BLEU '\n",
      " 'score of 0.98 and a ROUGE score of 0.99. These results demonstrate that '\n",
      " 'T5-small is a lightweight yet effective extractor of structured information. '\n",
      " 'In contrast, Llama-3.2-1B 1The code and data will be publicly available upon '\n",
      " 'publication at https://github.com/Sander445/StructuredPrompter.')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pprint\n",
    "\n",
    "def clean_academic_pdf_text(text):\n",
    "    # 1. Remove hyphenation across line breaks (e.g., \"val-\\nidation\" -> \"validation\")\n",
    "    text = re.sub(r'-\\n', '', text)\n",
    "    \n",
    "    # 2. Replace newlines within paragraphs with spaces\n",
    "    text = re.sub(r'(?<!\\n)\\n(?!\\n)', ' ', text)\n",
    "    \n",
    "    # 3. Collapse multiple newlines into paragraph breaks\n",
    "    text = re.sub(r'\\n+', '\\n\\n', text)\n",
    "    \n",
    "    # 4. Remove isolated page numbers (if any)\n",
    "    text = re.sub(r'^\\s*\\d+\\s*$', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # 5. Optional: remove figure/table captions\n",
    "    text = re.sub(r'Fig\\.\\s*\\d+.*?(?=\\n\\n)', '', text, flags=re.DOTALL)\n",
    "    \n",
    "    # 6. Strip leading/trailing whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "text = clean_academic_pdf_text(pdf_text[2])\n",
    "pprint.pprint(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df8f1c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f556e742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"text\": \"Dataset Plain\", \"label\": \"ORG\"}, {\"text\": \"T5\", \"label\": \"CARDINAL\"}, {\"text\": \"SDXL Generated\", \"label\": \"ORG\"}, {\"text\": \"Structured\", \"label\": \"PRODUCT\"}, {\"text\": \"Fig\", \"label\": \"PERSON\"}, {\"text\": \"2.\", \"label\": \"CARDINAL\"}, {\"text\": \"StructuredPrompter\", \"label\": \"ORG\"}, {\"text\": \"100\", \"label\": \"CARDINAL\"}, {\"text\": \"3.2\", \"label\": \"CARDINAL\"}, {\"text\": \"1\", \"label\": \"CARDINAL\"}, {\"text\": \"2\", \"label\": \"CARDINAL\"}, {\"text\": \"N\", \"label\": \"ORG\"}, {\"text\": \"Yi\", \"label\": \"PERSON\"}, {\"text\": \"five\", \"label\": \"CARDINAL\"}, {\"text\": \"five\", \"label\": \"CARDINAL\"}, {\"text\": \"T5\", \"label\": \"CARDINAL\"}, {\"text\": \"0.98\", \"label\": \"CARDINAL\"}, {\"text\": \"BLEU\", \"label\": \"ORG\"}, {\"text\": \"ROUGE\", \"label\": \"ORG\"}, {\"text\": \"Table 1\", \"label\": \"LAW\"}, {\"text\": \"Stable Diffusion XL\", \"label\": \"PRODUCT\"}, {\"text\": \"3.3\", \"label\": \"CARDINAL\"}, {\"text\": \"30\", \"label\": \"CARDINAL\"}, {\"text\": \"Image Quality\", \"label\": \"ORG\"}, {\"text\": \"the Inception Score\", \"label\": \"WORK_OF_ART\"}, {\"text\": \"31\", \"label\": \"CARDINAL\"}, {\"text\": \"4\", \"label\": \"CARDINAL\"}, {\"text\": \"4.1\", \"label\": \"CARDINAL\"}, {\"text\": \"three\", \"label\": \"CARDINAL\"}, {\"text\": \"40\", \"label\": \"DATE\"}, {\"text\": \"41\", \"label\": \"DATE\"}, {\"text\": \"42\", \"label\": \"CARDINAL\"}, {\"text\": \"4\", \"label\": \"CARDINAL\"}, {\"text\": \"8\", \"label\": \"CARDINAL\"}, {\"text\": \"Adam\", \"label\": \"PERSON\"}, {\"text\": \"10\", \"label\": \"CARDINAL\"}, {\"text\": \"0.01\", \"label\": \"CARDINAL\"}, {\"text\": \"PyTorch 2.5.1\", \"label\": \"LOC\"}, {\"text\": \"Transformers 4.50\", \"label\": \"PRODUCT\"}, {\"text\": \"GPU\", \"label\": \"ORG\"}, {\"text\": \"GitHub\", \"label\": \"ORG\"}, {\"text\": \"1\", \"label\": \"CARDINAL\"}, {\"text\": \"4.2\", \"label\": \"CARDINAL\"}, {\"text\": \"Table 1\", \"label\": \"LAW\"}, {\"text\": \"T5\", \"label\": \"CARDINAL\"}, {\"text\": \"500\", \"label\": \"CARDINAL\"}, {\"text\": \"BLEU\", \"label\": \"ORG\"}, {\"text\": \"0.98\", \"label\": \"CARDINAL\"}, {\"text\": \"ROUGE\", \"label\": \"ORG\"}, {\"text\": \"0.99\", \"label\": \"CARDINAL\"}, {\"text\": \"T5\", \"label\": \"CARDINAL\"}, {\"text\": \"Llama-3.2-1B\", \"label\": \"CARDINAL\"}, {\"text\": \"https://github.com/Sander445/StructuredPrompter\", \"label\": \"ORG\"}]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import json\n",
    "\n",
    "# Load English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process the text with spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract named entities and their labels\n",
    "meta_data = [{\"text\": ent.text, \"label\": ent.label_} for ent in doc.ents]\n",
    "\n",
    "\n",
    "# Convert meta data to JSON format\n",
    "meta_data_json = json.dumps(meta_data)\n",
    "\n",
    "print(meta_data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98e28b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ले गए संरचित जानकारी के साथ जोड़ा जाता है। 3.2। संवर्धित संकेतों को एक सादे '\n",
      " 'प्राकृतिक भाषा प्रॉम्प्ट एक्स को इनपुट के रूप में और GPT-4O-excracted संरचित '\n",
      " 'सूचना y को जमीनी सत्य के रूप में दिया जाता है, ')\n"
     ]
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# text = \"Hello, how are you?\"\n",
    "result = GoogleTranslator(source='en', target='hi').translate(text)\n",
    "pprint.pprint(result[300:500])  # \"Hola, ¿cómo estás?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77d384b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
